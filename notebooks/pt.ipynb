{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df852d25-b295-492a-a7fb-a782f958ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %env PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90104171-1458-4e66-bcd9-671ce4f4eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import hyclib as lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb8c91f-ab96-4833-ba6b-977ce94fbc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489 ns ± 9.55 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "472 ns ± 7.58 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "357 ns ± 3.88 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "2.62 µs ± 16.8 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "10.8 µs ± 102 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "7.15 µs ± 28.4 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def f1(a, n, m):\n",
    "    return a.reshape((1,) * n  + a.shape + (1,) * m)\n",
    "    \n",
    "def f2(a, n, m):\n",
    "    return a[(None,) * n + (slice(None),) * a.ndim + (None,) * m]\n",
    "\n",
    "def f3(a, n, m):\n",
    "    return a[(None,) * n + (Ellipsis,) + (None,) * m]\n",
    "\n",
    "n, m = 5, 7\n",
    "shape = (3,4,100,2,6)\n",
    "\n",
    "a = np.random.normal(size=shape)\n",
    "\n",
    "%timeit f1(a, n, m)\n",
    "%timeit f2(a, n, m)\n",
    "%timeit f3(a, n, m)\n",
    "\n",
    "a = torch.randn(*shape)\n",
    "\n",
    "%timeit f1(a, n, m)\n",
    "%timeit f2(a, n, m)\n",
    "%timeit f3(a, n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cd1ebce-7729-4a32-96d2-fcd4a08a4c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(torch.Size([3, 5]), torch.Size([4]), torch.Size([5, 7, 2])), (torch.Size([2]), torch.Size([3]), torch.Size([4]))]\n"
     ]
    }
   ],
   "source": [
    "sizes = [(3, 5, 2), (4, 3), (5, 7, 2, 4)]\n",
    "ndims = [2, 1, 3]\n",
    "tensors = [torch.rand(size) for size in sizes]\n",
    "print(list(zip(*[(tensor.shape[:ndim], tuple() if ndim is None else tensor.shape[ndim:])\n",
    "    for tensor, ndim in zip(tensors, ndims)])))\n",
    "pre_shapes, post_shapes = zip(*(\n",
    "    (tensor.shape[:ndim], tuple() if ndim is None else tensor.shape[ndim:])\n",
    "    for tensor, ndim in zip(tensors, ndims)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2179bb61-33ec-4359-825e-a874522ec219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(slice(None, None, None), slice(None, None, None), slice(None, None, None))\n"
     ]
    }
   ],
   "source": [
    "print((slice(None),) * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868172f3-69e7-49db-a803-78c95936bc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "lib.logging.basic_config()\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7357f72b-cbcc-49ef-863b-52f0ca6f14e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "weights should be 1-d and have the same length as input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# a_cpu, w_cpu = a.cpu(), w.cpu()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# a_np, w_np = a_cpu.numpy(), w_cpu.numpy()\u001b[39;00m\n\u001b[1;32m      7\u001b[0m lib\u001b[38;5;241m.\u001b[39mpt\u001b[38;5;241m.\u001b[39mbincount(a, weights\u001b[38;5;241m=\u001b[39mw)\n\u001b[0;32m----> 8\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# %timeit lib.pt.bincount(a)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# %timeit a.bincount()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# %timeit np.bincount(a_np, weights=w_np)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: weights should be 1-d and have the same length as input"
     ]
    }
   ],
   "source": [
    "N, M = 1_000_000, 1000\n",
    "a = torch.randint(M, size=(N,), device=device)\n",
    "w = torch.normal(mean=0.0, std=1.0, size=(2,N,), device=device)\n",
    "# a_cpu, w_cpu = a.cpu(), w.cpu()\n",
    "# a_np, w_np = a_cpu.numpy(), w_cpu.numpy()\n",
    "\n",
    "lib.pt.bincount(a, weights=w)\n",
    "a.bincount(weights=w)\n",
    "\n",
    "# %timeit lib.pt.bincount(a)\n",
    "# %timeit a.bincount()\n",
    "\n",
    "# %timeit lib.pt.bincount(a, weights=w)\n",
    "# %timeit a.bincount(weights=w)\n",
    "\n",
    "# %timeit lib.pt.bincount(a_cpu, weights=w_cpu)\n",
    "# %timeit a_cpu.bincount(weights=w_cpu)\n",
    "\n",
    "# %timeit np.bincount(a_np, weights=w_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca5e8f2-6c3f-4c22-9fc2-6329717f90ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_tuple(out):\n",
    "    return out if isinstance(out, tuple) else (out,)\n",
    "\n",
    "def test_unique(M, shape, O, dim, sorted, return_index, return_inverse, return_counts, first_index, device):\n",
    "    kwargs = {\n",
    "        'return_index': return_index,\n",
    "        'return_inverse': return_inverse,\n",
    "        'return_counts': return_counts,\n",
    "    }\n",
    "    np_kwargs = kwargs.copy()\n",
    "    np_kwargs['return_index'] = True # always use return_index=True in order to have stable sort\n",
    "    \n",
    "    t = torch.randint(M, size=shape)\n",
    "    if O > 0:\n",
    "        t = t.float()\n",
    "        indices = [torch.randint(D, size=(O,)) for D in shape]\n",
    "        t[tuple(indices)] = torch.nan\n",
    "    t = t.to(device)\n",
    "    a = t.cpu().numpy()\n",
    "\n",
    "    torch_results = [out_i for out_i in as_tuple(lib.pt.unique(t, dim=dim, sorted=sorted, first_index=first_index, **kwargs))]\n",
    "    np_results = as_tuple(np.unique(t.cpu().numpy(), axis=dim, equal_nan=False, **np_kwargs))\n",
    "    if not kwargs['return_index']:\n",
    "        np_results = list(np_results)\n",
    "        del np_results[1]\n",
    "\n",
    "    if not sorted:\n",
    "        if dim is None:\n",
    "            sort_idx = torch_results[0].argsort(stable=True)\n",
    "        else:\n",
    "            sort_idx = lib.pt.lexsort(torch_results[0].movedim(dim, -1).flip(0))\n",
    "        sort_idx_inv = lib.pt.inv_perm(sort_idx)\n",
    "\n",
    "    keys = ['x'] + [k for k, v in kwargs.items() if v]\n",
    "\n",
    "    for key, torch_result, np_result in zip(keys, torch_results, np_results):\n",
    "        if not first_index and key == 'return_index':\n",
    "            print(t.shape, torch_result.shape)\n",
    "            torch.testing.assert_close(torch_results[0], t.index_select(0 if dim is None else dim, torch_result), equal_nan=True)\n",
    "            continue # no need to check against numpy since the indices are not guaranteed to be the same due to non-determinism\n",
    "\n",
    "        if sorted:\n",
    "            torch.testing.assert_close(torch_result, torch.from_numpy(np_result).to(device), equal_nan=True)\n",
    "        else:\n",
    "            if key == 'return_inverse':\n",
    "                torch.testing.assert_close(sort_idx_inv[torch_result], torch.from_numpy(np_result).to(device), equal_nan=True)\n",
    "            else:\n",
    "                if dim is None or key != 'x':\n",
    "                    print(torch_result[sort_idx], torch.from_numpy(np_result).to(device))\n",
    "                    torch.testing.assert_close(torch_result[sort_idx], torch.from_numpy(np_result).to(device), equal_nan=True)\n",
    "                else:\n",
    "                    torch.testing.assert_close(torch_result.movedim(dim, 0)[sort_idx].movedim(0, dim), torch.from_numpy(np_result).to(device), equal_nan=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8be47c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU, non-deterministic\n",
      "tensor([18,  3, 24,  8, 10, 16, 21, 22, 17, 19])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([18,  3, 24,  8, 10, 16, 21, 22, 17, 19])\n",
      "tensor([48, 61, 55, 54, 10, 53, 51, 37, 60, 34])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([18,  3, 24,  8, 10, 16, 21, 22, 17, 19])\n",
      "tensor([18,  3, 24,  8, 10, 16, 21, 22, 17, 19])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([18,  3, 24,  8, 10, 16, 21, 22, 17, 19])\n",
      "tensor([18,  3, 24,  8, 10, 16, 21, 22, 17, 19])\n",
      "GPU, deterministic\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([18,  3, 24,  8, 10, 16, 21, 22, 17, 19])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "tensor([18,  3, 24,  8, 10, 16, 21, 22, 17, 19])\n",
      "tensor([81, 68, 55, 91, 89, 83, 88, 84, 69, 66])\n",
      "CPU, non-deterministic\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "CPU, deterministic\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n",
      "tensor([98, 99, 57, 96, 95, 83, 93, 84, 80, 87])\n"
     ]
    }
   ],
   "source": [
    "M, N, O = 10, 10, 100\n",
    "idx = torch.randint(M, size=(O,), device=device)\n",
    "t_new = torch.arange(O, device=device)\n",
    "idx_cpu = idx.cpu()\n",
    "t_new_cpu = t_new.cpu()\n",
    "\n",
    "print(\"GPU, non-deterministic\")\n",
    "for _ in range(N):\n",
    "    t = torch.zeros(M, dtype=torch.long, device=device)\n",
    "    t[idx] = t_new\n",
    "    print(t.cpu())\n",
    "    \n",
    "print(\"GPU, deterministic\")\n",
    "with lib.pt.use_deterministic_algorithms():\n",
    "    for _ in range(N):\n",
    "        t = torch.zeros(M, dtype=torch.long, device=device)\n",
    "        t[idx] = t_new\n",
    "        print(t.cpu())\n",
    "\n",
    "print(\"CPU, non-deterministic\")\n",
    "for _ in range(N):\n",
    "    t = torch.zeros(M, dtype=torch.long)\n",
    "    t[idx_cpu] = t_new_cpu\n",
    "    print(t)\n",
    "    \n",
    "print(\"CPU, deterministic\")\n",
    "with lib.pt.use_deterministic_algorithms():\n",
    "    for _ in range(N):\n",
    "        t = torch.zeros(M, dtype=torch.long)\n",
    "        t[idx_cpu] = t_new_cpu\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4736345d-4c1c-496a-9cbb-1e8b0c1fd2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([31, 59, 44, 14, 54,  4, 96, 62, 35, 64, 85, 86, 88, 95, 94, 83,  3, 60,\n",
      "        73, 10, 32, 98, 71, 93, 20, 99], device='mps:0') tensor([ 6, 25, 18, 14, 54,  1,  5, 33, 35, 64, 85, 86, 88, 15,  0,  9,  3, 60,\n",
      "        73, 10, 32, 98, 71, 93, 20, 99], device='mps:0')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not equal!\n\nMismatched elements: 9 / 26 (34.6%)\nGreatest absolute difference: 94 at index (14,)\nGreatest relative difference: inf at index (14,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m first_index \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m _ \u001b[39m=\u001b[39m test_unique(M, shape, O, dim, \u001b[39msorted\u001b[39;49m, return_index, return_inverse, return_counts, first_index, device)\n",
      "Cell \u001b[0;32mIn[13], line 50\u001b[0m, in \u001b[0;36mtest_unique\u001b[0;34m(M, shape, O, dim, sorted, return_index, return_inverse, return_counts, first_index, device)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     49\u001b[0m     \u001b[39mprint\u001b[39m(torch_result[sort_idx], torch\u001b[39m.\u001b[39mfrom_numpy(np_result)\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m---> 50\u001b[0m     torch\u001b[39m.\u001b[39;49mtesting\u001b[39m.\u001b[39;49massert_close(torch_result[sort_idx], torch\u001b[39m.\u001b[39;49mfrom_numpy(np_result)\u001b[39m.\u001b[39;49mto(device), equal_nan\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     torch\u001b[39m.\u001b[39mtesting\u001b[39m.\u001b[39massert_close(torch_result\u001b[39m.\u001b[39mmovedim(dim, \u001b[39m0\u001b[39m)[sort_idx]\u001b[39m.\u001b[39mmovedim(\u001b[39m0\u001b[39m, dim), torch\u001b[39m.\u001b[39mfrom_numpy(np_result)\u001b[39m.\u001b[39mto(device), equal_nan\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hyclib_nightly/lib/python3.9/site-packages/torch/testing/_comparison.py:1514\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1492\u001b[0m error_metas \u001b[39m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1493\u001b[0m     actual,\n\u001b[1;32m   1494\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     msg\u001b[39m=\u001b[39mmsg,\n\u001b[1;32m   1510\u001b[0m )\n\u001b[1;32m   1512\u001b[0m \u001b[39mif\u001b[39;00m error_metas:\n\u001b[1;32m   1513\u001b[0m     \u001b[39m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1514\u001b[0m     \u001b[39mraise\u001b[39;00m error_metas[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not equal!\n\nMismatched elements: 9 / 26 (34.6%)\nGreatest absolute difference: 94 at index (14,)\nGreatest relative difference: inf at index (14,)"
     ]
    }
   ],
   "source": [
    "M, shape, O, dim = (3, (100, 2), 20, 0)\n",
    "sorted = False\n",
    "return_index = True\n",
    "return_inverse = False\n",
    "return_counts = False\n",
    "first_index = True\n",
    "device = 'mps'\n",
    "_ = test_unique(M, shape, O, dim, sorted, return_index, return_inverse, return_counts, first_index, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51c49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3\n",
    "shape = (10000, 2)\n",
    "O = 20\n",
    "dim = 0\n",
    "\n",
    "t = torch.randint(M, size=shape)\n",
    "if O > 0:\n",
    "    t = t.float()\n",
    "    indices = [torch.randint(D, size=(O,)) for D in shape]\n",
    "    t[tuple(indices)] = torch.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a3bae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3 ms ± 100 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "17.3 ms ± 64 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lib.pt.unique(t, dim=dim, sorted=False, return_index=True, first_index=False)\n",
    "%timeit lib.pt.unique(t, dim=dim, sorted=False, return_index=True, first_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8238e39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.6 ms ± 25.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "16.6 ms ± 19.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lib.pt.unique(t, dim=dim, sorted=False, return_index=True, first_index=False)\n",
    "%timeit lib.pt.unique(t, dim=dim, sorted=False, return_index=True, first_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3daad4a-f1ed-46f3-b84f-da8731355bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59400\n",
      "21560\n"
     ]
    }
   ],
   "source": [
    "M, D, shape, O, dim = (4, 6, (99,100), 60_000, -1)\n",
    "t = torch.randint(M, size=(D,*shape))\n",
    "if O > 0:\n",
    "    t = t.float()\n",
    "    indices = [torch.randint(D, size=(O,))]\n",
    "    indices += [torch.randint(N, size=(O,)) for N in shape]\n",
    "    t[tuple(indices)] = torch.nan\n",
    "t = t.to(device)\n",
    "a = t.cpu().numpy()\n",
    "\n",
    "pt_idx = lib.pt.lexsort(t, dim=dim)\n",
    "np_idx = np.lexsort(a, axis=dim)\n",
    "\n",
    "print(t.numel())\n",
    "print(t[~t.isnan()].numel())\n",
    "\n",
    "torch.testing.assert_close(pt_idx, torch.from_numpy(np_idx).to(device), equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "663ff2ef-fe8b-442b-9dda-46140de62d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M, N, D, O = 2, 100_000, 20, 1_000\n",
    "# M, N, D, O = 3, 100, 2, 10\n",
    "M, N, D, O = 5, 10_000, 5, 1_000\n",
    "t = torch.randint(M, size=(N,D)).float()\n",
    "idx_0 = torch.randint(N, size=(O,))\n",
    "idx_1 = torch.randint(D, size=(O,))\n",
    "t[idx_0, idx_1] = torch.nan\n",
    "t = t.to(device)\n",
    "t_cpu = t.cpu()\n",
    "a = t.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb001d39-cc8e-470f-aac6-0ce19f6e9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 0\n",
    "kwargs = {\n",
    "    'return_index': True,\n",
    "    'return_inverse': True,\n",
    "    'return_counts': True,\n",
    "}\n",
    "\n",
    "torch_results = [t for t in as_tuple(lib.pt.unique(t, dim=dim, **kwargs))]\n",
    "np_results = as_tuple(np.unique(t.cpu().numpy(), axis=dim, equal_nan=False, **kwargs))\n",
    "\n",
    "for torch_result, np_result in zip(torch_results, np_results):\n",
    "    torch.testing.assert_close(torch_result, torch.from_numpy(np_result).to(device), equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06a09c49-84e9-453c-a7d4-b89241451a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3902\n"
     ]
    }
   ],
   "source": [
    "dim = 0\n",
    "kwargs = {\n",
    "    'return_index': True,\n",
    "    'return_inverse': True,\n",
    "    'return_counts': True,\n",
    "}\n",
    "\n",
    "def as_tuple(out):\n",
    "    return out if isinstance(out, tuple) else (out,)\n",
    "\n",
    "torch_results = [t for t in as_tuple(lib.pt.unique(t, dim=dim, **kwargs))]\n",
    "np_results = as_tuple(np.unique(t.cpu().numpy(), axis=dim, equal_nan=False, **kwargs))\n",
    "print(len(torch_results[0]))\n",
    "\n",
    "sort_idx = lib.pt.lexsort(torch_results[0].t().flip(0))\n",
    "sort_idx_inv = lib.pt.inv_perm(sort_idx)\n",
    "\n",
    "keys = ['x'] + [k for k, v in kwargs.items() if v]\n",
    "\n",
    "for key, torch_result, np_result in zip(keys, torch_results, np_results):\n",
    "    if key == 'return_inverse':\n",
    "        torch.testing.assert_close(sort_idx_inv[torch_result], torch.from_numpy(np_result).to(device), equal_nan=True)\n",
    "    else:\n",
    "        torch.testing.assert_close(torch_result[sort_idx], torch.from_numpy(np_result).to(device), equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575a336c-ac45-4037-8994-0adac1db793a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.098428 s\n",
       "File: /Users/hoyinchau/local_documents/research/hyclib/hyclib/pt/core.py\n",
       "Function: _unique_sorted at line 30\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    30                                           def _unique_sorted(x, dim=None, return_index=False, return_inverse=False, return_counts=False):\n",
       "    31         1          0.0      0.0      0.0      if dim is None:\n",
       "    32                                                   x = x.reshape(-1)\n",
       "    33                                                   dim = 0\n",
       "    34                                                   \n",
       "    35                                               # reshape to a 2D tensor where we compute unique rows\n",
       "    36         1     100000.0 100000.0      0.1      x = x.movedim(dim, 0)\n",
       "    37         1       3000.0   3000.0      0.0      shape = x.shape\n",
       "    38         1      20000.0  20000.0      0.0      x = x.reshape(shape[0], -1)\n",
       "    39                                               \n",
       "    40         1   59399000.0 59399000.0     60.3      sort_idx = lexsort(x.t().flip(0))\n",
       "    41         1     918000.0 918000.0      0.9      x = x[sort_idx]\n",
       "    42                                               \n",
       "    43         1       1000.0   1000.0      0.0      if return_index:\n",
       "    44         1   36436000.0 36436000.0     37.0          x, inverse, counts = torch.unique_consecutive(x, dim=0, return_inverse=True, return_counts=True)\n",
       "    45         1     517000.0 517000.0      0.5          tot_counts = torch.cat((counts.new_zeros(1), counts.int().cumsum(dim=0).long()))[:-1] # cast to int32 due to MPS limitation\n",
       "    46         1     386000.0 386000.0      0.4          index = torch.arange(len(inverse), device=tot_counts.device)[tot_counts]\n",
       "    47                                                   \n",
       "    48         1       1000.0   1000.0      0.0          out = {'x': x, 'index': index}\n",
       "    49         1       1000.0   1000.0      0.0          if return_inverse:\n",
       "    50         1       1000.0   1000.0      0.0              out['inverse'] = inverse\n",
       "    51         1          0.0      0.0      0.0          if return_counts:\n",
       "    52         1       1000.0   1000.0      0.0              out['counts'] = counts\n",
       "    53                                               else:\n",
       "    54                                                   ret = torch.unique_consecutive(x, dim=0, return_inverse=return_inverse, return_counts=return_counts)\n",
       "    55                                                   ret = list(ret) if isinstance(ret, tuple) else [ret]\n",
       "    56                                                   \n",
       "    57                                                   out = {'x': ret.pop(0)}\n",
       "    58                                                   if return_inverse:\n",
       "    59                                                       out['inverse'] = ret.pop(0)\n",
       "    60                                                   if return_counts:\n",
       "    61                                                       out['counts'] = ret.pop(0)\n",
       "    62                                                       \n",
       "    63                                               # correct for the fact that we reshaped and sorted before computing unqiue\n",
       "    64         1      32000.0  32000.0      0.0      out['x'] = out['x'].reshape(-1, *shape[1:]).movedim(0, dim)\n",
       "    65         1          0.0      0.0      0.0      if return_index or return_inverse:\n",
       "    66         1       1000.0   1000.0      0.0          if return_index:\n",
       "    67         1     211000.0 211000.0      0.2              out['index'] = sort_idx[out['index']]\n",
       "    68         1          0.0      0.0      0.0          if return_inverse:\n",
       "    69         1     287000.0 287000.0      0.3              sort_idx_inv = inv_perm(sort_idx)\n",
       "    70         1     110000.0 110000.0      0.1              out['inverse'] = out['inverse'][sort_idx_inv]\n",
       "    71                                               \n",
       "    72         1       1000.0   1000.0      0.0      if len(out) == 1:\n",
       "    73                                                   return out['x']\n",
       "    74         1       2000.0   2000.0      0.0      return tuple(out.values())\n",
       "\n",
       "Total time: 0.098452 s\n",
       "File: /Users/hoyinchau/local_documents/research/hyclib/hyclib/pt/core.py\n",
       "Function: unique at line 76\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    76                                           def unique(x, dim=None, sorted=True, return_index=False, return_inverse=False, return_counts=False):\n",
       "    77         1       1000.0   1000.0      0.0      if sorted or x.device.type == 'mps': # unique_dim currently not implemented for MPS, so do _unique_sorted instead, which does not uses unique_consecutive instead of unique_dim\n",
       "    78         1   98451000.0 98451000.0    100.0          return _unique_sorted(x, dim=dim, return_index=return_index, return_inverse=return_inverse, return_counts=return_counts)\n",
       "    79                                               \n",
       "    80                                               if dim is None:\n",
       "    81                                                   x = x.reshape(-1)\n",
       "    82                                                   dim = 0\n",
       "    83                                               \n",
       "    84                                               # reshape to a 2D tensor where we compute unique rows\n",
       "    85                                               x = x.movedim(dim, 0)\n",
       "    86                                               shape = x.shape\n",
       "    87                                               x = x.reshape(shape[0], -1)\n",
       "    88                                               \n",
       "    89                                               # sort rows such that rows with nans comes after rows without nans.\n",
       "    90                                               # This avoids torch.unique bug when dim is not None and input has nan.\n",
       "    91                                               isnan = x.isnan().any(dim=1)\n",
       "    92                                               x = torch.cat((x[~isnan], x[isnan]), dim=0)\n",
       "    93                                           \n",
       "    94                                               if return_index:\n",
       "    95                                                   # code copied from https://github.com/pytorch/pytorch/issues/36748#issuecomment-1474368922\n",
       "    96                                                   x, inverse, counts = torch.unique(x, dim=0, return_inverse=True, return_counts=True)\n",
       "    97                                                   inv_sort_idx = inverse.argsort(stable=True)\n",
       "    98                                                   tot_counts = torch.cat((counts.new_zeros(1), counts.cumsum(dim=0)))[:-1]\n",
       "    99                                                   index = inv_sort_idx[tot_counts]\n",
       "   100                                                   \n",
       "   101                                                   out = {'x': x, 'index': index}\n",
       "   102                                                   if return_inverse:\n",
       "   103                                                       out['inverse'] = inverse\n",
       "   104                                                   if return_counts:\n",
       "   105                                                       out['counts'] = counts\n",
       "   106                                               else:\n",
       "   107                                                   ret = torch.unique(x, dim=0, return_inverse=return_inverse, return_counts=return_counts)\n",
       "   108                                                   ret = list(ret) if isinstance(ret, tuple) else [ret]\n",
       "   109                                                   out = {'x': ret.pop(0)}\n",
       "   110                                                   if return_inverse:\n",
       "   111                                                       out['inverse'] = ret.pop(0)\n",
       "   112                                                   if return_counts:\n",
       "   113                                                       out['counts'] = ret.pop(0)\n",
       "   114                                               \n",
       "   115                                               # correct for the fact that we reshaped and sorted before computing unqiue\n",
       "   116                                               out['x'] = out['x'].reshape(-1, *shape[1:]).movedim(0, dim)\n",
       "   117                                               if return_index or return_inverse:\n",
       "   118                                                   sort_idx = torch.cat(((~isnan).nonzero(), isnan.nonzero())).squeeze()\n",
       "   119                                                   if return_index:\n",
       "   120                                                       out['index'] = sort_idx[out['index']]\n",
       "   121                                                   if return_inverse:\n",
       "   122                                                       sort_idx_inv = inv_perm(sort_idx)\n",
       "   123                                                       out['inverse'] = out['inverse'][sort_idx_inv]\n",
       "   124                                               \n",
       "   125                                               if len(out) == 1:\n",
       "   126                                                   return out['x']\n",
       "   127                                               return tuple(out.values())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f lib.pt.unique -f lib.pt._unique_sorted lib.pt.unique(t, dim=dim, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3848096b-4a78-4bed-ad2d-11d2665debbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([95389, 20])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib.pt.unique(t, dim=dim, **kwargs)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d9b076d-3106-4dba-b106-cafa5637d338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 ms ± 219 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "167 ms ± 1.34 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "313 ms ± 8.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lib.pt.unique(t, dim=dim, **kwargs)\n",
    "%timeit lib.pt.unique(t_cpu, dim=dim, sorted=False, **kwargs)\n",
    "%timeit lib.pt.unique(t_cpu, dim=dim, sorted=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "771191d5-d2d7-40c0-8e84-f90a19ce8bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 ms ± 9.39 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.unique(a, axis=dim, equal_nan=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0418b2e-cb95-4eed-8cc9-933db323e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.6 ms ± 113 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "144 ms ± 300 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "150 ms ± 386 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "226 ms ± 5.65 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "111 ms ± 1.44 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lib.pt.unique(t, dim=dim, **kwargs)\n",
    "%timeit lib.pt.unique(t_cpu, dim=dim, sorted=False, **kwargs)\n",
    "%timeit lib.pt.unique(t_cpu, dim=dim, sorted=True, **kwargs)\n",
    "%timeit np.unique(a, axis=dim, equal_nan=False, **kwargs)\n",
    "%timeit lib.np.unique_rows(a, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "981d53cf-32ad-4473-a013-95383cef3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoyinchau/opt/anaconda3/envs/hyclib/lib/python3.9/site-packages/torch/masked/maskedtensor/core.py:299: UserWarning: max is not implemented in __torch_dispatch__ for MaskedTensor.\n",
      "If you would like this operator to be supported, please file an issue for a feature request at https://github.com/pytorch/maskedtensor/issues with a minimal reproducible code snippet.\n",
      "In the case that the semantics for the operator are not trivial, it would be appreciated to also include a proposal for the semantics.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "no implementation found for 'torch._ops.aten.max.default' on types that implement __torch_dispatch__: [<class 'torch.masked.maskedtensor.core.MaskedTensor'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMaskedTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hyclib/lib/python3.9/site-packages/torch/masked/maskedtensor/core.py:274\u001b[0m, in \u001b[0;36mMaskedTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mTypeError\u001b[0m: no implementation found for 'torch._ops.aten.max.default' on types that implement __torch_dispatch__: [<class 'torch.masked.maskedtensor.core.MaskedTensor'>]"
     ]
    }
   ],
   "source": [
    "torch.masked.MaskedTensor(torch.tensor([1,2,3]), torch.tensor([True, True, False])).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "503a275e-d1a4-4a3d-b939-0dd0e02032e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    t = torch.normal(mean=0, std=1, size=(10,), device='mps')\n",
    "    out_1 = lib.pt.stats.bin(t.cpu(), bins=3)[0]\n",
    "    out_2 = lib.pt.stats.bin(t, bins=3)[0].cpu()\n",
    "    out_3 = lib.sp.stats.bin(t.cpu().numpy(), bins=3)[0]\n",
    "    assert (out_1 == out_2.cpu()).all() and (out_1.numpy() == out_3).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fcd52dd0-03ed-43b8-a747-2b7eae192139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([3, 2, 3, 3, 3, 1, 3, 2, 2, 3]), tensor([    nan, -1.2486, -0.3541,  0.5404,     nan]), tensor([-1.6958, -0.8013,  0.0931,  0.9876]))\n",
      "(tensor([3, 2, 3, 3, 3, 1, 3, 2, 2, 3], device='mps:0'), tensor([    nan, -1.2486, -0.3541,  0.5404,     nan], device='mps:0'), tensor([-1.6958, -0.8013,  0.0931,  0.9876], device='mps:0'))\n",
      "(array([3, 2, 3, 3, 3, 1, 3, 2, 2, 3]), array([        nan, -1.24855185, -0.3540917 ,  0.54036844,         nan]), array([-1.695782  , -0.8013218 ,  0.09313837,  0.98759854], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "out_1 = lib.pt.stats.bin(a.cpu(), bins=3)\n",
    "out_2 = lib.pt.stats.bin(a, bins=3)\n",
    "out_3 = lib.sp.stats.bin(a.cpu(), bins=3)\n",
    "print(out_1)\n",
    "print(out_2)\n",
    "print(out_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c29e4d14-49e2-403e-a03d-22890f6af8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N = 100, 100000\n",
    "\n",
    "# bins = [-2.5,-2,-1,0,1,2,3.0]\n",
    "bins = 100\n",
    "arr = np.random.normal(size=N)\n",
    "indices = np.random.randint(N, size=M)\n",
    "arr[indices] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b9c6799-9588-4b70-8037-07463b5559da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array([-0.79857488, -0.29282404,  0.29925128, ..., -0.66033549,\n       -0.61356288,  0.04627834]) contains non-finite values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m binnumbers, centers, edges \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbin\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnan_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(arr)\n\u001b[1;32m      4\u001b[0m tbinnumbers, tcenters, tedges \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mpt\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mbin(t, bins\u001b[38;5;241m=\u001b[39mbins, nan_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/local_documents/research/hyclib/build/__editable__.hyclib-0.1.6-py3-none-any/hyclib/sp/stats.py:372\u001b[0m, in \u001b[0;36mbin\u001b[0;34m(sample, bins, range, nan_policy)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mrange\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28mrange\u001b[39m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mrange\u001b[39m]\n\u001b[0;32m--> 372\u001b[0m bin_nums, centers, edges \u001b[38;5;241m=\u001b[39m \u001b[43mbin_dd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnan_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bin_nums[\u001b[38;5;241m0\u001b[39m], centers[\u001b[38;5;241m0\u001b[39m], edges[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/local_documents/research/hyclib/build/__editable__.hyclib-0.1.6-py3-none-any/hyclib/sp/stats.py:332\u001b[0m, in \u001b[0;36mbin_dd\u001b[0;34m(sample, bins, range, expand_binnumbers, nan_policy)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# If bins was an integer-like object, now it is an actual Python int.\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# NOTE: for _bin_edges(), see e.g. gh-11365\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nan_policy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(sample)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m contains non-finite values.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sample,))\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# `Ndim` is the number of dimensions (e.g. `2` for `binned_statistic_2d`)\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# `Dlen` is the length of elements along each dimension.\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# This code is based on np.histogramdd\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# `sample` is an ND-array.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: array([-0.79857488, -0.29282404,  0.29925128, ..., -0.66033549,\n       -0.61356288,  0.04627834]) contains non-finite values."
     ]
    }
   ],
   "source": [
    "binnumbers, centers, edges = lib.sp.stats.bin(arr, bins=bins, nan_policy='raise')\n",
    "\n",
    "t = torch.tensor(arr)\n",
    "tbinnumbers, tcenters, tedges = lib.pt.stats.bin(t, bins=bins, nan_policy='raise')\n",
    "\n",
    "pbinnumbers, pedges = pd.cut(arr, bins=bins, retbins=True, labels=False, right=False)\n",
    "\n",
    "# print(binnumbers)\n",
    "# print(tbinnumbers.numpy())\n",
    "# print(pbinnumbers)\n",
    "# print(centers)\n",
    "# print(tcenters.numpy())\n",
    "# print(binnumbers[np.isnan(arr)])\n",
    "# print(tbinnumbers.numpy()[np.isnan(arr)])\n",
    "# print(pbinnumbers[np.isnan(arr)])\n",
    "\n",
    "torch.testing.assert_close(torch.from_numpy(binnumbers), tbinnumbers)\n",
    "torch.testing.assert_close(torch.from_numpy(centers), tcenters, equal_nan=True)\n",
    "torch.testing.assert_close(torch.from_numpy(edges), tedges)\n",
    "\n",
    "isnan = np.isnan(pbinnumbers)\n",
    "np.testing.assert_allclose(binnumbers[~isnan], pbinnumbers[~isnan] + 1)\n",
    "if isinstance(bins, numbers.Number):\n",
    "    r = np.nanmax(arr) - np.nanmin(arr)\n",
    "    edges[-1] = edges[-1] + r * 0.001\n",
    "np.testing.assert_allclose(edges, pedges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302e7dc-bcbb-4351-bd9d-6f3212ebe81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-hyclib]",
   "language": "python",
   "name": "conda-env-anaconda3-hyclib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
