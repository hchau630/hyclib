{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c71206-566b-4beb-852f-a857d1c4455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2974770-a7fe-4b76-8f9c-5012836bec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "\n",
    "import hyclib as lib\n",
    "import hyclib.core.configurable as conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f42598-6850-4b39-a050-f4ac8db92a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlib.Path('/tmp/pytest-of-hc3190/pytest-27/test_dict_save_load0/config.pkl').is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c130defa-376d-4f51-8cef-16bcc85c6c56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': [1, 2], 'sub_module.x': 0, 'sub_module.a': [0, 1, 2.1]}\n",
      "{'y': [1, 2], 'sub_module.x': 0, 'sub_module.a': [5.5, 1, 2.1]}\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "class SubModule(conf.Configurable, torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = torch.nn.Parameter(torch.ones(2,2))\n",
    "        self.x = conf.Parameter(dtype=int)\n",
    "        self.a = conf.Parameter([0,1,2.1])\n",
    "        \n",
    "class Module(conf.Configurable, torch.nn.Module):\n",
    "    def __init__(self, y, z):\n",
    "        super().__init__()\n",
    "        self.sub_module = SubModule()\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "m = Module(conf.Parameter([1,2]), torch.nn.Parameter(torch.zeros(2,2)))\n",
    "config_dict = m.config_dict()\n",
    "print(config_dict)\n",
    "config_dict['sub_module.a'][0] = 5.5\n",
    "m.load_config_dict(config_dict)\n",
    "config_dict = m.config_dict()\n",
    "print(config_dict)\n",
    "print(m.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ab5a712f-2958-46d0-ac46-a20176cd29c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(5, 0))\n"
     ]
    }
   ],
   "source": [
    "hi = torch.zeros((5,0))\n",
    "print(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "79ca1b21-d70a-422a-9d55-ebe130b27b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid(conf.Configurable, torch.Tensor):\n",
    "    def __new__(cls, *args, data=None, require_grads=False, **kwargs):\n",
    "        # Reference: https://discuss.pytorch.org/t/subclassing-torch-longtensor/100377/3\n",
    "        if data is None:\n",
    "            data = get_grid(*args, **kwargs)\n",
    "        return torch.Tensor._make_subclass(cls, data, require_grads) \n",
    "    \n",
    "    def __init__(self, extents, shape=None, dxs=None, w_dims=None, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        if w_dims is None:\n",
    "            w_dims = []\n",
    "\n",
    "        self._extents = conf.Parameter(extentse)\n",
    "        self._w_dims = conf.Parameter(w_dims)\n",
    "        \n",
    "    @property\n",
    "    def tensor(self):\n",
    "        return self.as_subclass(torch.Tensor) # return a pure torch.Tensor without all the extra attribute\n",
    "    \n",
    "    @property\n",
    "    def extents(self):\n",
    "        return self._extents\n",
    "    \n",
    "    @property\n",
    "    def w_dims(self):\n",
    "        return self._w_dims\n",
    "    \n",
    "def get_grid(extents, shape=None, dxs=None, w_dims=None, method='linspace', device='cpu'):\n",
    "    \"\"\"\n",
    "    Get a grid (i.e. a tensor with shape (n_1, n_2, ..., n_N, n_1+...+n_N) where grid[*idx,:] are coordinates)\n",
    "    by specifying the extents in each dimension and the shape (n_1, ..., n_N).\n",
    "    \n",
    "    Parameters:\n",
    "        extents: list of tuples of scalars (2,) or list of scalars - If list of tuples, each i-th tuple\n",
    "                 indicates the lower and upper bound of the i-th dimension. If list of scalars, the lower\n",
    "                 and upper bound are interpreted as (-scalar/2, scalar/2) for method='linspace' and\n",
    "                 (0, scalar) for method='arange'.\n",
    "        shape: tuple - shape of the grid, ignored if method is not 'linspace'\n",
    "        dxs: tuple - step sizes in each dimension, ignored if method is not 'arange'. If None, defaults to\n",
    "             step sizes of 1 along each dimension.\n",
    "        w_dims: list of ints - a list of the dimensions along which the endpoint is not included, which is\n",
    "                useful for dimensions which are periodic/wrapped (w in w_dims stands for wrapped). Ignored\n",
    "                if method='arange'.\n",
    "        method: 'linspace' or 'arange'. Specifies whether torch.linspace or torch.arange is used.\n",
    "        device: The device on which the grid is created.\n",
    "        \n",
    "    Returns:\n",
    "        grid: torch.Tensor\n",
    "        \n",
    "    \"\"\"\n",
    "    assert all([len(extent) == 2 for extent in extents if isinstance(extent, tuple)])\n",
    "    if method == 'linspace':\n",
    "        if shape is None:\n",
    "            raise ValueError(\"shape must be provided when method='linspace'\")\n",
    "        else:\n",
    "            assert len(extents) == len(shape)\n",
    "    if method == 'arange':\n",
    "        if dxs is None:\n",
    "            dxs = [1 for _ in range(len(extents))]\n",
    "        else:\n",
    "            assert len(extents) == len(dxs)\n",
    "    if w_dims is None:\n",
    "        w_dims = []\n",
    "    else:\n",
    "        assert isinstance(w_dims, list)\n",
    "    if len(w_dims) > 0:\n",
    "        assert max(w_dims) < len(extents)\n",
    "    \n",
    "    if method == 'linspace':\n",
    "        extents = [extent if isinstance(extent, tuple) else (-extent/2, extent/2) for extent in extents]\n",
    "        endpoints = [False if i in w_dims else True for i in range(len(extents))]\n",
    "        grids_per_dim = [linspace(extent[0],extent[1],N,endpoint,device=device) for extent, N, endpoint in zip(extents, shape, endpoints)]\n",
    "    elif method == 'arange':\n",
    "        extents = [extent if isinstance(extent, tuple) else (0, extent) for extent in extents]\n",
    "        grids_per_dim = [torch.arange(extent[0],extent[1],dx,device=device) for extent, dx in zip(extents, dxs)]\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    grid = torch.stack(torch.meshgrid(*grids_per_dim, indexing='ij'), dim=-1)\n",
    "    return grid\n",
    "\n",
    "def linspace(start, end, steps, endpoint=True, **kwargs):\n",
    "    if endpoint:\n",
    "        return torch.linspace(start, end, steps, **kwargs)\n",
    "    else:\n",
    "        return torch.linspace(start, end, steps+1, **kwargs)[:-1] # exclude endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "444627ef-00a7-401c-bd8e-0d002bc07f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_extents': [5.0, 5.0], '_w_dims': []}\n"
     ]
    }
   ],
   "source": [
    "grid = Grid([5.0,5.0],shape=(5,5))\n",
    "print(grid.config_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8fc1ec6f-b983-41ee-92d2-c51ed14b017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "in child\n",
      "in super\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"HERE\")\n",
    "        self.x = 1\n",
    "    \n",
    "    def __setattr__(self, name, value):\n",
    "        print(\"in super\")\n",
    "        super().__setattr__(name, value)\n",
    "        \n",
    "class B(A):\n",
    "    def __setattr__(self, name, value):\n",
    "        print(\"in child\")\n",
    "        super().__setattr__(name, value)\n",
    "        \n",
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "43adab68-ed17-47b6-ae51-4fcb1620ee62",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'float' as parameter 'x' (torch.nn.Parameter or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17823/411268644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# a.W = 3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/utils/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m                 raise TypeError(\"cannot assign '{}' as parameter '{}' \"\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                 \u001b[0;34m\"(torch.nn.Parameter or None expected)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                                 .format(torch.typename(value), name))\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'float' as parameter 'x' (torch.nn.Parameter or None expected)"
     ]
    }
   ],
   "source": [
    "class A(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = torch.nn.Linear(2,2)\n",
    "        self.x = torch.nn.Parameter(torch.tensor(2.0))\n",
    "        \n",
    "a = A()\n",
    "# a.W = 3.0\n",
    "a.x = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc1bc7db-ad45-4137-9818-5642a7af0e99",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidConfigParameter",
     "evalue": "data 10 is not json serializable, try converting it to a compatible object type. If not possible, you can set is_jsonable=False, but then you can't save the config dict as json.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidConfigParameter\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17823/3937028849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/ctn/users/hc3190/utils/utils/configurable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dtype, is_jsonable)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOverflowError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 raise exceptions.InvalidConfigParameter(f\"data {data} is not json serializable,\" \n\u001b[0m\u001b[1;32m     23\u001b[0m                                                         \u001b[0;34m\" try converting it to a compatible object type.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                         \u001b[0;34m\" If not possible, you can set is_jsonable=False,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidConfigParameter\u001b[0m: data 10 is not json serializable, try converting it to a compatible object type. If not possible, you can set is_jsonable=False, but then you can't save the config dict as json."
     ]
    }
   ],
   "source": [
    "hi = conf.Parameter(torch.tensor(10))\n",
    "print(hi.data, hi.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31f16180-5f3f-4c76-835c-04d4e859c3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('x.weight', tensor([[ 0.5398, -0.6444],\n",
      "        [ 0.4426,  0.5372]])), ('x.bias', tensor([-0.1677, -0.0337]))])\n",
      "Parameter containing:\n",
      "tensor([[0.5398, 1.0000],\n",
      "        [0.4426, 0.5372]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.5398, 1.0000],\n",
      "        [0.4426, 0.5372]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.5398, -2.0000],\n",
      "        [ 0.4426,  0.5372]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class Hi(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = torch.nn.Linear(2,2)\n",
    "        \n",
    "hi = Hi()\n",
    "state_dict = hi.state_dict()\n",
    "print(state_dict)\n",
    "state_dict['x.weight'][0,1] = 1.0\n",
    "print(hi.x.weight)\n",
    "hi.load_state_dict(state_dict)\n",
    "print(hi.x.weight)\n",
    "state_dict['x.weight'][0,1] = -2.0\n",
    "print(hi.x.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be29e833-4c2c-4822-8ea7-d8dcf7ac8d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "hi = {'a': 1}\n",
    "print('a' in hi.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12218c-15f2-4a99-88b6-963c6d6e9da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-hyclib]",
   "language": "python",
   "name": "conda-env-anaconda3-hyclib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
